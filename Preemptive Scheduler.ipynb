{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6233ba2-4200-4990-935f-a1790e1e20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum, auto\n",
    "from typing import Any, Callable, Deque, Dict, List, Optional, Tuple\n",
    "from collections import deque\n",
    "import heapq\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# -------- Events --------\n",
    "\n",
    "class EventType(Enum):\n",
    "    ARRIVAL = auto()\n",
    "    DEPARTURE = auto()\n",
    "\n",
    "@dataclass(order=True)\n",
    "class Event:\n",
    "    time: float\n",
    "    order: int\n",
    "    type: EventType = field(compare=False)\n",
    "    payload: Dict[str, Any] = field(compare=False, default_factory=dict)\n",
    "    is_valid: bool = field(compare=False, default=True) # NEW: Flag for cancellation\n",
    "\n",
    "\n",
    "# -------- Core domain --------\n",
    "\n",
    "@dataclass\n",
    "class Job:\n",
    "    id: int\n",
    "    cls: str\n",
    "    t_arrival: float\n",
    "    q_arrival: float\n",
    "    t_service_start: Optional[float] = None\n",
    "    t_departure: Optional[float] = None\n",
    "    # optional: path trace [(station_id, queue_id, t_enter, t_start, t_leave)]\n",
    "    trace: List[Tuple[str, str, float, Optional[float], Optional[float]]] = field(default_factory=list)\n",
    "\n",
    "\n",
    "class Queue:\n",
    "    \"\"\"\n",
    "    FIFO queue by default. Replace with a priority queue if you need.\n",
    "    \"\"\"\n",
    "    def __init__(self, station_id: str, queue_id: str):\n",
    "        self.station_id = station_id\n",
    "        self.queue_id = queue_id\n",
    "        self._buf: Deque[Job] = deque()\n",
    "\n",
    "    def push(self, job: Job, t: float) -> None:\n",
    "        job.trace.append((self.station_id, self.queue_id, t, None, None))\n",
    "        self._buf.append(job)\n",
    "\n",
    "    def pop(self) -> Optional[Job]:\n",
    "        if not self._buf:\n",
    "            return None\n",
    "        return self._buf.popleft()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._buf)\n",
    "\n",
    "    def peek(self) -> Optional[Job]:\n",
    "        return self._buf[0] if self._buf else None\n",
    "\n",
    "    def peek_n(self, n: int) -> Optional[Job]:\n",
    "        # n = 0 -> head, 1 -> second, ...\n",
    "        if n < 0 or n >= len(self._buf):\n",
    "            return None\n",
    "        # deque supports O(n) indexing; n is tiny (<= #free servers), so this is fine\n",
    "        return self._buf[n]\n",
    "\n",
    "\n",
    "class Server:\n",
    "    \"\"\"\n",
    "    Single server (non-preemptive). Station owns multiple of these.\n",
    "    \"\"\"\n",
    "    #service sampler is a function that maps a job to a float.\n",
    "    #def svc1(job):  # e.g., class-specific service rates\n",
    "    #return rng.exponential(1/ (1.5 if job.cls==\"A\" else 1.0))\n",
    "    def __init__(self, server_id: str, service_sampler: Callable[[Job], float]):\n",
    "        self.server_id = server_id\n",
    "        self.service_sampler = service_sampler\n",
    "        self.busy: bool = False\n",
    "        self.job: Optional[Job] = None\n",
    "        self.t_busy_until: float = math.inf\n",
    "        self.departure_event: Optional[Event] = None # NEW: Link to the departure event\n",
    "\n",
    "    def start_service(self, job: Job, t: float) -> float:\n",
    "        \"\"\"Start service and return departure time.\"\"\"\n",
    "        assert not self.busy\n",
    "        self.busy = True\n",
    "        self.job = job\n",
    "        job.t_service_start = t\n",
    "        # mark trace start time\n",
    "        if job.trace and job.trace[-1][3] is None:\n",
    "            st, qid, t_enter, _, t_leave = job.trace[-1]\n",
    "            job.trace[-1] = (st, qid, t_enter, t, t_leave)\n",
    "\n",
    "        s = max(0.0, float(self.service_sampler(job)))\n",
    "        dep_time = t + s\n",
    "        self.t_busy_until = dep_time\n",
    "        return dep_time\n",
    "\n",
    "    def complete(self, t: float):\n",
    "        assert self.busy and self.job is not None\n",
    "        job = self.job\n",
    "        # mark trace leave time for this stage\n",
    "        if job.trace and job.trace[-1][4] is None:\n",
    "            st, qid, t_enter, t_start, _ = job.trace[-1]\n",
    "            job.trace[-1] = (st, qid, t_enter, t_start, t)\n",
    "        self.busy = False\n",
    "        self.job = None\n",
    "        self.t_busy_until = math.inf\n",
    "        return job\n",
    "\n",
    "class Station:\n",
    "    \"\"\"\n",
    "    Station with c servers and multiple queues.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        station_id: str,\n",
    "        queues: Dict[str, Queue],\n",
    "        servers: List[Server],\n",
    "    ):\n",
    "        self.station_id = station_id\n",
    "        self.queues = queues         # queue_id -> Queue\n",
    "        self.servers = servers       # list of Server\n",
    "\n",
    "    def free_servers(self) -> List[Server]:\n",
    "        return [s for s in self.servers if not s.busy]\n",
    "\n",
    "    def total_queue_len(self) -> int:\n",
    "        return sum(len(q) for q in self.queues.values())\n",
    "\n",
    "    def queue_lengths(self) -> Dict[str, int]:\n",
    "        return {qid: len(q) for qid, q in self.queues.items()}\n",
    "\n",
    "\n",
    "# -------- Arrivals and Routing --------\n",
    "\n",
    "class ArrivalProcess:\n",
    "    \"\"\"\n",
    "    External arrival process targeting (station_id, queue_id).\n",
    "    For exponential inter-arrivals: sampler() returns Exp(Î»).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_station: str,\n",
    "        target_queue: str,\n",
    "        interarrival_sampler: Callable[[], float],\n",
    "        job_class: str,\n",
    "    ):\n",
    "        self.station_id = target_station\n",
    "        self.queue_id = target_queue\n",
    "        self.interarrival_sampler = interarrival_sampler\n",
    "        self.job_class = job_class\n",
    "        self.next_time: float = 0.0\n",
    "\n",
    "    def schedule_next(self, t_now: float) -> float:\n",
    "        self.next_time = t_now + max(0.0, float(self.interarrival_sampler()))\n",
    "        return self.next_time\n",
    "\n",
    "\n",
    "# -------- Policy interface --------\n",
    "\n",
    "class SchedulingPolicy:\n",
    "    \"\"\"\n",
    "    Centralized policy: at a decision epoch (e.g., after arrivals or a departure),\n",
    "    assign jobs to some/all free servers across the network.\n",
    "\n",
    "    Must return a mapping: (server) -> (queue) from which to take the next job.\n",
    "    The simulator will pop a job from that queue and start it on that server.\n",
    "    \"\"\"\n",
    "    def decide(\n",
    "        self,\n",
    "        net: NetworkLike,                  # duck-typed: see Network below\n",
    "        t: float,\n",
    "        free_servers: List[Tuple[Station, Server]],\n",
    "    ) -> Dict[Server, Queue]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "# -------- Network (orchestrator) --------\n",
    "\n",
    "class Network:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stations: Dict[str, Station],\n",
    "        arrivals: List[ArrivalProcess],\n",
    "        router: Router,\n",
    "        policy: SchedulingPolicy,\n",
    "        rng: Optional[np.random.Generator] = None,\n",
    "    ):\n",
    "        self.stations = stations\n",
    "        self.arrivals = arrivals\n",
    "        self.router = router\n",
    "        self.policy = policy\n",
    "        self.rng = rng or np.random.default_rng(0)\n",
    "\n",
    "        self.t: float = 0.0\n",
    "        self._event_q: List[Event] = []\n",
    "        self._eid: int = 0\n",
    "        self._job_id_seq: int = 0\n",
    "        self.completed_jobs: int = 0\n",
    "        self.sum_sojourn: float = 0.0\n",
    "        self.exited_jobs: list = []\n",
    "        self._seeded: bool = False\n",
    "\n",
    "    def schedule(self, time: float, etype: EventType, payload: Dict[str, Any]) -> Event:\n",
    "        self._eid += 1\n",
    "        ev = Event(time=time, order=self._eid, type=etype, payload=payload)\n",
    "        heapq.heappush(self._event_q, ev)\n",
    "        return ev\n",
    "\n",
    "    def run(self, until_time: Optional[float] = None, until_jobs: Optional[int] = None) -> None:\n",
    "        if not self._seeded:\n",
    "            for ap in self.arrivals:\n",
    "                t_next = ap.schedule_next(self.t)\n",
    "                self.schedule(t_next, EventType.ARRIVAL, {\"ap\": ap})\n",
    "            self._seeded = True\n",
    "\n",
    "        while self._event_q:\n",
    "            if until_time is not None and self._event_q[0].time > until_time:\n",
    "                break\n",
    "\n",
    "            ev = heapq.heappop(self._event_q)\n",
    "            \n",
    "            if not ev.is_valid:\n",
    "                continue\n",
    "\n",
    "            if until_jobs is not None and self.completed_jobs >= until_jobs:\n",
    "                heapq.heappush(self._event_q, ev)\n",
    "                break\n",
    "\n",
    "            dt = ev.time - self.t\n",
    "            if dt > 0:\n",
    "                for st in self.stations.values():\n",
    "                    if not hasattr(st, \"_ql_area\"): st._ql_area = {qid: 0.0 for qid in st.queues}\n",
    "                    if not hasattr(st, \"_sl_area\"): st._sl_area = 0.0\n",
    "                    for qid, q in st.queues.items():\n",
    "                        st._ql_area[qid] += len(q) * dt\n",
    "                    num_busy_servers = sum(1 for srv in st.servers if srv.busy)\n",
    "                    st._sl_area += num_busy_servers * dt\n",
    "            \n",
    "            self.t = ev.time\n",
    "\n",
    "            # Use the event's order as its ID for departure validation\n",
    "            current_event_id = ev.order\n",
    "\n",
    "            if ev.type == EventType.ARRIVAL:\n",
    "                self._on_arrival(ev.payload[\"ap\"])\n",
    "            elif ev.type == EventType.DEPARTURE:\n",
    "                self._on_departure(ev.payload[\"station_id\"], ev.payload[\"server_idx\"], current_event_id)\n",
    "            \n",
    "            self._decision_epoch()\n",
    "\n",
    "    def _on_arrival(self, ap: ArrivalProcess) -> None:\n",
    "        job = Job(id=self._next_job_id(), cls=ap.job_class, t_arrival=self.t, q_arrival=self.t)\n",
    "        st = self.stations[ap.station_id]\n",
    "        q = st.queues[ap.queue_id]\n",
    "        q.push(job, self.t)\n",
    "        t_next = ap.schedule_next(self.t)\n",
    "        self.schedule(t_next, EventType.ARRIVAL, {\"ap\": ap})\n",
    "    \n",
    "    def _on_departure(self, station_id: str, server_idx: int, event_id: int) -> None:\n",
    "        st = self.stations[station_id]\n",
    "        srv = st.servers[server_idx]\n",
    "        \n",
    "        # Stale event check: if the server's active departure event doesn't match this one, ignore it\n",
    "        if not srv.busy or not srv.departure_event or srv.departure_event.order != event_id:\n",
    "             return\n",
    "        \n",
    "        job = srv.complete(self.t)\n",
    "        srv.departure_event = None\n",
    "        \n",
    "        nxt = self.router.route(job, station_id, self.t)\n",
    "        if nxt is None:\n",
    "            job.t_departure = self.t\n",
    "            self.completed_jobs += 1\n",
    "            self.sum_sojourn += (job.t_departure - job.t_arrival)\n",
    "            self.exited_jobs.append(job) \n",
    "        else:\n",
    "            next_st_id, next_q_id = nxt\n",
    "            # Find the queue a job belongs to based on its class\n",
    "            # This is a simplification and may need adjustment for complex routings\n",
    "            preempted_job_q_id = f\"Q{job.cls}\"\n",
    "            if preempted_job_q_id in self.stations[next_st_id].queues:\n",
    "                job.q_arrival = self.t\n",
    "                self.stations[next_st_id].queues[preempted_job_q_id].push(job, self.t)\n",
    "            else: # Fallback for more complex cases\n",
    "                self.stations[next_st_id].queues[next_q_id].push(job, self.t)\n",
    "\n",
    "    def _decision_epoch(self) -> None:\n",
    "        assignments = self.policy.decide(self, self.t, self.stations)\n",
    "\n",
    "        for st_id, st in self.stations.items():\n",
    "            for i, srv in enumerate(st.servers):\n",
    "                ideal_queue = assignments.get(srv)\n",
    "                ideal_job = ideal_queue.peek() if ideal_queue else None\n",
    "\n",
    "                if srv.busy:\n",
    "                    current_job = srv.job\n",
    "                    if not ideal_job or (current_job and ideal_job.id == current_job.id):\n",
    "                        continue\n",
    "                    \n",
    "                    preempted_job = srv.complete(self.t)\n",
    "                    if srv.departure_event:\n",
    "                        srv.departure_event.is_valid = False\n",
    "                    srv.departure_event = None\n",
    "                    \n",
    "                    source_queue_id = f\"Q{preempted_job.cls}\"\n",
    "                    if source_queue_id in st.queues:\n",
    "                         st.queues[source_queue_id].push(preempted_job, self.t)\n",
    "                    else:\n",
    "                        print(f\"Warning: Could not find queue for preempted job class {preempted_job.cls}\")\n",
    "\n",
    "                if not srv.busy and ideal_queue and len(ideal_queue) > 0:\n",
    "                    job_to_start = ideal_queue.pop()\n",
    "                    dep_time = srv.start_service(job_to_start, self.t)\n",
    "                    dep_event = self.schedule(dep_time, EventType.DEPARTURE, {\"station_id\": st_id, \"server_idx\": i})\n",
    "                    srv.departure_event = dep_event\n",
    "\n",
    "    def _next_job_id(self) -> int:\n",
    "        self._job_id_seq += 1\n",
    "        return self._job_id_seq\n",
    "\n",
    "    def queue_length(self, station_id: str, queue_id: str) -> int:\n",
    "        return len(self.stations[station_id].queues[queue_id])\n",
    "\n",
    "    def station_queue_lengths(self, station_id: str) -> Dict[str, int]:\n",
    "        st = self.stations[station_id]\n",
    "        return {qid: len(q) for qid, q in st.queues.items()}\n",
    "\n",
    "    def total_queue_lengths(self) -> Dict[Tuple[str, str], int]:\n",
    "        out = {}\n",
    "        for sid, st in self.stations.items():\n",
    "            for qid, q in st.queues.items():\n",
    "                out[(sid, qid)] = len(q)\n",
    "        return out\n",
    "\n",
    "    def mean_sojourn(self) -> float:\n",
    "        return self.sum_sojourn / self.completed_jobs if self.completed_jobs else float(\"nan\")\n",
    "# -------- Utility samplers (Exp arrivals/services) --------\n",
    "\n",
    "def exp_interarrival(rate: float, rng: np.random.Generator) -> Callable[[], float]:\n",
    "    assert rate > 0\n",
    "    return lambda: rng.exponential(1.0 / rate)\n",
    "\n",
    "def exp_service(mu: float, rng: np.random.Generator) -> Callable[[Job], float]:\n",
    "    assert mu > 0\n",
    "    return lambda job: rng.exponential(1.0 / mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83016278-d6e5-4a69-88ae-5b15b472aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBFSPolicy(SchedulingPolicy):\n",
    "    \"\"\"\n",
    "    Last-Buffer First-Serve (LBFS) Policy for a Preemptive System.\n",
    "    At each decision epoch, this policy identifies the non-empty queue with the\n",
    "    highest class index at each station. It then assigns all servers at that\n",
    "    station to this single highest-priority queue.\n",
    "    \"\"\"\n",
    "    def decide(self, net: Network, t: float, stations: Dict[str, Station]) -> Dict[Server, Queue]:\n",
    "        assignments: Dict[Server, Queue] = {}\n",
    "        for st_id, st in stations.items():\n",
    "            best_q: Optional[Queue] = None\n",
    "            max_cls_id = -1\n",
    "\n",
    "            # Find the single highest-priority non-empty queue for the station\n",
    "            for q in st.queues.values():\n",
    "                if len(q) > 0:\n",
    "                    try:\n",
    "                        cls_id = int(q.queue_id.replace(\"Q\", \"\"))\n",
    "                        if cls_id > max_cls_id:\n",
    "                            max_cls_id = cls_id\n",
    "                            best_q = q\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            # If a priority queue was found, assign all servers at this station to it\n",
    "            if best_q:\n",
    "                for srv in st.servers:\n",
    "                    assignments[srv] = best_q\n",
    "                        \n",
    "        return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6b1259-7390-4418-bf1a-371ce9d7c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCFSPolicy(SchedulingPolicy):\n",
    "    \"\"\"\n",
    "    First-Come, First-Serve (FCFS) Policy - System-Wide for a Preemptive System.\n",
    "    At each decision epoch, for each station, this policy finds all available\n",
    "    jobs (at the head of each queue), sorts them by their original network\n",
    "    entry time (t_arrival), and assigns servers to the oldest available jobs.\n",
    "    \"\"\"\n",
    "    def decide(self, net: Network, t: float, stations: Dict[str, Station]) -> Dict[Server, Queue]:\n",
    "        assignments: Dict[Server, Queue] = {}\n",
    "        for st_id, st in stations.items():\n",
    "            # Find all available jobs at the station (job, and its queue)\n",
    "            available_jobs = []\n",
    "            for q in st.queues.values():\n",
    "                if len(q) > 0:\n",
    "                    job = q.peek()\n",
    "                    available_jobs.append((job, q))\n",
    "            \n",
    "            # Sort the jobs by their original system entry time (oldest first)\n",
    "            available_jobs.sort(key=lambda item: item[0].t_arrival)\n",
    "            \n",
    "            # Assign servers to the highest-priority (oldest) jobs\n",
    "            for i, srv in enumerate(st.servers):\n",
    "                if i < len(available_jobs):\n",
    "                    # Assign this server to the i-th oldest job's queue\n",
    "                    job, queue = available_jobs[i]\n",
    "                    assignments[srv] = queue\n",
    "        return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4493c9a3-2bac-4062-84ae-adc41046c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedSixClassNetwork(Network):\n",
    "    \"\"\"\n",
    "    \"Extended Six-Class Queueing Network\" from Figure 4\n",
    "    of Dai and Gluzman (2022).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 policy: SchedulingPolicy,\n",
    "                 *,\n",
    "                 L: int, # Number of stations\n",
    "                 seed: int = 0,\n",
    "                 ):\n",
    "        if not L >= 2:\n",
    "            raise ValueError(\"L must be an integer >= 2 for this network.\")\n",
    "        rng = np.random.default_rng(seed)\n",
    "        lam = 9.0 / 140.0\n",
    "        mu_rates = { \n",
    "            1: 1.0 / 8.0, 2: 1.0 / 2.0, 3: 1.0 / 4.0,\n",
    "            4: 1.0 / 6.0, 5: 1.0 / 7.0, 6: 1.0 / 1.0,\n",
    "        }\n",
    "\n",
    "        def service_sampler(job: Job) -> float:\n",
    "            class_idx = int(job.cls)\n",
    "            key = (class_idx - 1) % 6 + 1\n",
    "            rate = mu_rates[key]\n",
    "            return rng.exponential(1.0 / rate)\n",
    "\n",
    "        stations: Dict[str, Station] = {}\n",
    "        for i in range(1, L + 1):\n",
    "            sid = f\"S{i}\"\n",
    "            station_queues: Dict[str, Queue] = {}\n",
    "            for k in range(1, 4):\n",
    "                class_id = 3 * (i - 1) + k\n",
    "                qid = f\"Q{class_id}\"\n",
    "                station_queues[qid] = Queue(sid, qid)\n",
    "            station_servers = [Server(f\"{sid}-s0\", service_sampler)]\n",
    "            stations[sid] = Station(sid, station_queues, station_servers)\n",
    "\n",
    "        arrival_sampler = lambda: rng.exponential(1.0 / lam)\n",
    "        ap1 = ArrivalProcess(\"S1\", \"Q1\", arrival_sampler, job_class=\"1\")\n",
    "        ap3 = ArrivalProcess(\"S1\", \"Q3\", arrival_sampler, job_class=\"3\")\n",
    "\n",
    "        class _Router:\n",
    "            def route(self, job: Job, station_id: str, t: float) -> Optional[Tuple[str, str]]:\n",
    "                station_num = int(station_id.replace(\"S\", \"\"))\n",
    "                class_num = int(job.cls)\n",
    "                if station_num < L:\n",
    "                    next_class = class_num + 3\n",
    "                    next_station = station_num + 1\n",
    "                    job.cls = str(next_class)\n",
    "                    return (f\"S{next_station}\", f\"Q{next_class}\")\n",
    "                elif station_num == L:\n",
    "                    if class_num == 3 * (L - 1) + 1:\n",
    "                        job.cls = \"2\"\n",
    "                        return (\"S1\", \"Q2\")\n",
    "                    else:\n",
    "                        return None\n",
    "                return None\n",
    "\n",
    "        super().__init__(\n",
    "            stations=stations,\n",
    "            arrivals=[ap1, ap3],\n",
    "            router=_Router(),\n",
    "            policy=policy,\n",
    "            rng=rng,\n",
    "        )\n",
    "        self._params = dict(L=L, lam=lam, mu_rates=mu_rates)\n",
    "\n",
    "    # --- Metrics and Experiment Helpers ---\n",
    "\n",
    "    def run_and_get_batch_means_stats(\n",
    "        self,\n",
    "        warmup_time: float,\n",
    "        num_batches: int,\n",
    "        batch_duration: float\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Runs a simulation with warmup and uses the batch means method to\n",
    "        get a stable estimate of the mean number of jobs in the system.\n",
    "        \"\"\"\n",
    "        print(f\"Running warmup for {warmup_time:.0f} time units...\")\n",
    "        self.run(until_time=warmup_time)\n",
    "        print(\"Warmup complete. Starting batch means measurement...\")\n",
    "\n",
    "        batch_means = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # Reset the area counters for queues and servers at the start of the batch\n",
    "            for st in self.stations.values():\n",
    "                if hasattr(st, \"_ql_area\"):\n",
    "                    st._ql_area = {qid: 0.0 for qid in st.queues}\n",
    "                if hasattr(st, \"_sl_area\"): # NEW\n",
    "                    st._sl_area = 0.0       # NEW\n",
    "\n",
    "            t_batch_start = self.t\n",
    "            self.run(until_time=t_batch_start + batch_duration)\n",
    "            \n",
    "            # Calculate the mean jobs for this batch (queues + servers)\n",
    "            total_area_this_batch = 0\n",
    "            for st in self.stations.values():\n",
    "                if hasattr(st, \"_ql_area\"):\n",
    "                    total_area_this_batch += sum(st._ql_area.values())\n",
    "                if hasattr(st, \"_sl_area\"): # NEW\n",
    "                    total_area_this_batch += st._sl_area # NEW\n",
    "            \n",
    "            mean_jobs_this_batch = total_area_this_batch / batch_duration\n",
    "            batch_means.append(mean_jobs_this_batch)\n",
    "            \n",
    "            # Optional: uncomment to see progress\n",
    "            # print(f\"Batch {i+1}/{num_batches} complete. Mean jobs: {mean_jobs_this_batch:.3f}\")\n",
    "\n",
    "        # Calculate statistics over the batch means\n",
    "        mean_of_means = np.mean(batch_means)\n",
    "        std_of_means = np.std(batch_means, ddof=1)\n",
    "        \n",
    "        # 95% CI half-width using z=1.96 (appropriate for num_batches >= 30)\n",
    "        ci_half_width = 1.96 * (std_of_means / np.sqrt(num_batches))\n",
    "\n",
    "        print(\"Measurement complete.\")\n",
    "        return {\n",
    "            \"mean_jobs_in_system\": mean_of_means,\n",
    "            \"ci_half_width\": ci_half_width,\n",
    "            \"std_dev_of_batch_means\": std_of_means,\n",
    "            \"num_batches\": num_batches,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c9e70e-9fcf-44b6-8909-2a400cea3d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simulating the 6-Class Network with LBFS Policy (using Batch Means) ---\n",
      "Running warmup for 10000 time units...\n",
      "Warmup complete. Starting batch means measurement...\n",
      "Measurement complete.\n",
      "\n",
      "--- Final Simulation Results ---\n",
      "Mean number of jobs in system: 14.284\n",
      "95% Confidence Interval: +/- 0.608\n",
      "Result: 14.284 Â± 0.608\n",
      "\n",
      "\n",
      "--- Simulating the 6-Class Network with FIFO Policy (using Batch Means) ---\n",
      "Running warmup for 10000 time units...\n",
      "Warmup complete. Starting batch means measurement...\n",
      "Measurement complete.\n",
      "\n",
      "--- Final Simulation Results ---\n",
      "Mean number of jobs in system: 18.496\n",
      "95% Confidence Interval: +/- 0.755\n",
      "Result: 18.496 Â± 0.755\n"
     ]
    }
   ],
   "source": [
    "def run6Class(NUM_STATIONS, seed):\n",
    "    \n",
    "    print(f\"--- Simulating the {3*NUM_STATIONS}-Class Network with LBFS Policy (using Batch Means) ---\")\n",
    "    \n",
    "    lbfs_policy = LBFSPolicy()\n",
    "    network = ExtendedSixClassNetwork(policy=lbfs_policy, L=NUM_STATIONS, seed=seed)\n",
    "    results = network.run_and_get_batch_means_stats(\n",
    "        warmup_time=10000.0,\n",
    "        num_batches=50,\n",
    "        batch_duration=100000.0\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Final Simulation Results ---\")\n",
    "    print(f\"Mean number of jobs in system: {results['mean_jobs_in_system']:.3f}\")\n",
    "    print(f\"95% Confidence Interval: +/- {results['ci_half_width']:.3f}\")\n",
    "    print(f\"Result: {results['mean_jobs_in_system']:.3f} Â± {results['ci_half_width']:.3f}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"--- Simulating the {3*NUM_STATIONS}-Class Network with FIFO Policy (using Batch Means) ---\")\n",
    "    \n",
    "    fifo_policy = FCFSPolicy()\n",
    "    network = ExtendedSixClassNetwork(policy=fifo_policy, L=NUM_STATIONS, seed=seed)\n",
    "    results = network.run_and_get_batch_means_stats(\n",
    "        warmup_time=10000.0,\n",
    "        num_batches=50,\n",
    "        batch_duration=100000.0\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Final Simulation Results ---\")\n",
    "    print(f\"Mean number of jobs in system: {results['mean_jobs_in_system']:.3f}\")\n",
    "    print(f\"95% Confidence Interval: +/- {results['ci_half_width']:.3f}\")\n",
    "    print(f\"Result: {results['mean_jobs_in_system']:.3f} Â± {results['ci_half_width']:.3f}\")\n",
    "\n",
    "run6Class(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46b5f1-db6c-4c8b-9688-ca331c012c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
